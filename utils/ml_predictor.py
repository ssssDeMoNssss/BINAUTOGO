"""
BINAUTOGO - Machine Learning Predictor
–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª –∫ DeepSeek —á–µ—Ä–µ–∑ ML
"""

import logging
import pickle
from pathlib import Path
from datetime import datetime
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.preprocessing import StandardScaler
import xgboost as xgb
import lightgbm as lgb

logger = logging.getLogger('BINAUTOGO.MLPredictor')


class MLPredictor:
    """
    Machine Learning –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä
    –û–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –¥–æ–ø–æ–ª–Ω—è–µ—Ç DeepSeek
    """
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ML –º–æ–¥–µ–ª–µ–π"""
        # –ê–Ω—Å–∞–º–±–ª—å –º–æ–¥–µ–ª–µ–π
        self.models = {
            'random_forest': RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                random_state=42
            ),
            'gradient_boost': GradientBoostingClassifier(
                n_estimators=100,
                max_depth=5,
                random_state=42
            ),
            'xgboost': xgb.XGBClassifier(
                n_estimators=100,
                max_depth=5,
                random_state=42
            ),
            'lightgbm': lgb.LGBMClassifier(
                n_estimators=100,
                max_depth=5,
                random_state=42
            )
        }
        
        self.scaler = StandardScaler()
        self.is_trained = False
        
        # –•—Ä–∞–Ω–∏–ª–∏—â–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        self.training_data = []
        
        # –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
        self.models_dir = Path('data/ml_models')
        self.models_dir.mkdir(parents=True, exist_ok=True)
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        self._load_models()
        
        logger.info("‚úÖ MLPredictor –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def extract_features(self, signal, market_data=None) -> np.ndarray:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ —Å–∏–≥–Ω–∞–ª–∞
        
        Args:
            signal: Trading signal
            market_data: –†—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            –ú–∞—Å—Å–∏–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        """
        features = []
        
        # –ü—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ —Å–∏–≥–Ω–∞–ª–∞
        features.append(signal.confidence)
        features.append(1 if signal.direction == 'buy' else 0)
        features.append(signal.quantity)
        features.append((signal.take_profit - signal.price) / signal.price)  # –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –ø—Ä–∏–±—ã–ª—å
        features.append((signal.price - signal.stop_loss) / signal.price)  # –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π —É–±—ã—Ç–æ–∫
        
        # Risk/Reward
        risk = abs(signal.price - signal.stop_loss)
        reward = abs(signal.take_profit - signal.price)
        features.append(reward / risk if risk > 0 else 0)
        
        # –ü—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞ DeepSeek
        features.append(signal.analysis.confidence)
        features.append(signal.analysis.risk_score / 10)  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        
        # –ü—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ market_data (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if market_data:
            indicators = market_data.get('indicators', {})
            features.append(indicators.get('rsi_5m', 50) / 100)  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            features.append(indicators.get('rsi_1h', 50) / 100)
            features.append(indicators.get('volume_ratio', 1.0))
            features.append(indicators.get('bb_position', 0.5))
            
            # –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã
            features.append(market_data.get('price_change_24h', 0) / 100)
        else:
            # –ó–∞–≥–ª—É—à–∫–∏ –µ—Å–ª–∏ –Ω–µ—Ç market_data
            features.extend([0.5, 0.5, 1.0, 0.5, 0.0])
        
        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        now = datetime.now()
        features.append(now.hour / 24)  # –ß–∞—Å –¥–Ω—è
        features.append(now.weekday() / 7)  # –î–µ–Ω—å –Ω–µ–¥–µ–ª–∏
        
        return np.array(features).reshape(1, -1)
    
    def predict_trade_success(self, signal, market_data=None) -> float:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ —Å–¥–µ–ª–∫–∏
        
        Args:
            signal: Trading signal
            market_data: –†—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            
        Returns:
            –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞ (0-1)
        """
        if not self.is_trained:
            logger.debug("ML –º–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É")
            return signal.confidence
        
        try:
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            features = self.extract_features(signal, market_data)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            features_scaled = self.scaler.transform(features)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ—Ç –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
            predictions = []
            for model_name, model in self.models.items():
                try:
                    pred = model.predict_proba(features_scaled)[0][1]  # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∞ 1
                    predictions.append(pred)
                except Exception as e:
                    logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è {model_name}: {e}")
            
            # –£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π (–∞–Ω—Å–∞–º–±–ª—å)
            if predictions:
                avg_prediction = np.mean(predictions)
                logger.debug(f"ML –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {avg_prediction:.2%}")
                return avg_prediction
            else:
                return signal.confidence
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ ML –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            return signal.confidence
    
    def add_training_data(self, signal, order, outcome=None):
        """
        –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        
        Args:
            signal: Trading signal
            order: –ò—Å–ø–æ–ª–Ω–µ–Ω–Ω—ã–π –æ—Ä–¥–µ—Ä
            outcome: –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–¥–µ–ª–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        """
        features = self.extract_features(signal)
        
        # –ï—Å–ª–∏ outcome –Ω–µ —É–∫–∞–∑–∞–Ω, –∂–¥—ë–º –∑–∞–∫—Ä—ã—Ç–∏—è –ø–æ–∑–∏—Ü–∏–∏
        self.training_data.append({
            'features': features,
            'signal': signal,
            'order': order,
            'outcome': outcome,
            'timestamp': datetime.now()
        })
        
        logger.debug(f"–î–æ–±–∞–≤–ª–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –í—Å–µ–≥–æ: {len(self.training_data)}")
    
    def train_on_history(self, trades_history: list):
        """
        –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –∏—Å—Ç–æ—Ä–∏–∏ —Å–¥–µ–ª–æ–∫
        
        Args:
            trades_history: –ò—Å—Ç–æ—Ä–∏—è —Å–¥–µ–ª–æ–∫ –∏–∑ PortfolioTracker
        """
        if len(trades_history) < 50:
            logger.info(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {len(trades_history)}/50")
            return
        
        logger.info(f"ü§ñ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è ML –Ω–∞ {len(trades_history)} —Å–¥–µ–ª–∫–∞—Ö...")
        
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            X = []
            y = []
            
            for trade in trades_history:
                if trade['status'] != 'closed':
                    continue
                
                # –£–ø—Ä–æ—â—ë–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏
                features = [
                    trade.get('signal_confidence', 0.5),
                    1 if trade['side'] == 'buy' else 0,
                    trade['quantity'],
                    (trade['exit_price'] - trade['entry_price']) / trade['entry_price'],
                    0.03,  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã–π risk
                    2.0,   # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã–π R/R
                    trade.get('signal_confidence', 0.5),
                    5 / 10,  # –°—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫
                    0.5, 0.5, 1.0, 0.5, 0.0,  # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (—Å—Ä–µ–¥–Ω–∏–µ)
                    12 / 24,  # –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è
                    2 / 7     # –°—Ä–µ–¥–Ω–∏–π –¥–µ–Ω—å –Ω–µ–¥–µ–ª–∏
                ]
                
                X.append(features)
                
                # –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: 1 –µ—Å–ª–∏ –ø—Ä–∏–±—ã–ª—å, 0 –µ—Å–ª–∏ —É–±—ã—Ç–æ–∫
                y.append(1 if trade['pnl'] > 0 else 0)
            
            X = np.array(X)
            y = np.array(y)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            X_scaled = self.scaler.fit_transform(X)
            
            # –û–±—É—á–µ–Ω–∏–µ –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
            trained_count = 0
            for model_name, model in self.models.items():
                try:
                    model.fit(X_scaled, y)
                    
                    # –û—Ü–µ–Ω–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏
                    accuracy = model.score(X_scaled, y)
                    logger.info(f"  ‚úÖ {model_name}: —Ç–æ—á–Ω–æ—Å—Ç—å {accuracy:.2%}")
                    
                    trained_count += 1
                except Exception as e:
                    logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è {model_name}: {e}")
            
            if trained_count > 0:
                self.is_trained = True
                logger.info(f"‚úÖ ML –º–æ–¥–µ–ª–∏ –æ–±—É—á–µ–Ω—ã! ({trained_count}/4)")
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
                self._save_models()
            else:
                logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –Ω–∏ –æ–¥–Ω—É –º–æ–¥–µ–ª—å")
            
        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
    
    def _save_models(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
            for model_name, model in self.models.items():
                model_path = self.models_dir / f"{model_name}.pkl"
                with open(model_path, 'wb') as f:
                    pickle.dump(model, f)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ scaler
            scaler_path = self.models_dir / "scaler.pkl"
            with open(scaler_path, 'wb') as f:
                pickle.dump(self.scaler, f)
            
            logger.info(f"üíæ ML –º–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {self.models_dir}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")
    
    def _load_models(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ñ–∞–π–ª–æ–≤
            scaler_path = self.models_dir / "scaler.pkl"
            if not scaler_path.exists():
                logger.debug("–°–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                return
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ scaler
            with open(scaler_path, 'rb') as f:
                self.scaler = pickle.load(f)
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
            loaded_count = 0
            for model_name in self.models.keys():
                model_path = self.models_dir / f"{model_name}.pkl"
                if model_path.exists():
                    with open(model_path, 'rb') as f:
                        self.models[model_name] = pickle.load(f)
                    loaded_count += 1
            
            if loaded_count > 0:
                self.is_trained = True
                logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ ML –º–æ–¥–µ–ª–µ–π: {loaded_count}/4")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π: {e}")
    
    def get_feature_importance(self) -> dict:
        """–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        if not self.is_trained:
            return {}
        
        feature_names = [
            'confidence', 'direction', 'quantity', 'potential_profit',
            'potential_loss', 'risk_reward', 'deepseek_confidence',
            'risk_score', 'rsi_5m', 'rsi_1h', 'volume_ratio',
            'bb_position', 'price_change_24h', 'hour', 'weekday'
        ]
        
        importance = {}
        
        try:
            # –ë–µ—Ä—ë–º Random Forest –¥–ª—è feature importance
            rf_model = self.models.get('random_forest')
            if rf_model and hasattr(rf_model, 'feature_importances_'):
                for name, imp in zip(feature_names, rf_model.feature_importances_):
                    importance[name] = float(imp)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏: {e}")
        
        return importance


# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
if __name__ == "__main__":
    logging.basicConfig(level=logging.DEBUG)
    
    from core.signal_generator import TradingSignal
    from core.deepseek_analyzer import MarketAnalysis
    
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ MLPredictor...\n")
    
    predictor = MLPredictor()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞
    test_analysis = MarketAnalysis(
        symbol='BTC/USDT',
        direction='bullish',
        confidence=0.75,
        entry_price=43500.0,
        target_price=45000.0,
        stop_loss=42500.0,
        position_size=0.15,
        reasoning='–¢–µ—Å—Ç',
        risk_score=5,
        timeframe='1h',
        timestamp=datetime.now()
    )
    
    test_signal = TradingSignal(
        symbol='BTC/USDT',
        direction='buy',
        signal_type='long',
        strength=0.75,
        price=43500.0,
        quantity=0.1,
        stop_loss=42500.0,
        take_profit=45000.0,
        confidence=0.75,
        analysis=test_analysis,
        reasoning='–¢–µ—Å—Ç',
        timestamp=datetime.now()
    )
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    prediction = predictor.predict_trade_success(test_signal)
    print(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {prediction:.2%}")
    
    # –°–∏–º—É–ª—è—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    mock_history = []
    for i in range(100):
        mock_history.append({
            'timestamp': datetime.now(),
            'symbol': 'BTC/USDT',
            'side': 'buy',
            'quantity': 0.1,
            'entry_price': 43000 + i*10,
            'exit_price': 43500 + i*10,
            'pnl': 50 if i % 3 != 0 else -20,
            'signal_confidence': 0.7,
            'status': 'closed'
        })
    
    # –û–±—É—á–µ–Ω–∏–µ
    predictor.train_on_history(mock_history)
    
    # –ü–æ–≤—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    prediction_after = predictor.predict_trade_success(test_signal)
    print(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è: {prediction_after:.2%}")
    
    print("\n‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à—ë–Ω!")
